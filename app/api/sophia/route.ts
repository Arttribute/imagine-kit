import OpenAI from "openai";
import { NextResponse } from "next/server";

const API_KEY = process.env.OPENAI_API_KEY;
const openai = new OpenAI({
  apiKey: API_KEY,
});

export async function POST(request: Request) {
  try {
    const requestBody = await request.json();
    const { message, nodes, edges, appData, interactionData } = requestBody;

    // Construct the prompt
    const prompt = `
    You are Sophia, an AI copilot integrated into a node-based editor called ImagineKit. Your role is to assist users in creating and improving their node diagrams for AI-driven apps.
    The user has provided the following message:
    "${message}"

    The current state of the node editor is as follows:
    - Nodes:
    ${JSON.stringify(nodes, null, 2)}
    - Edges:
    ${JSON.stringify(edges, null, 2)}

    The app metadata is:
    ${JSON.stringify(appData, null, 2)}

    The interaction history is:
    ${JSON.stringify(interactionData, null, 2)}

    Your task is to:
    - Analyze the user's message and the current node editor state.
    - Generate suggestions to improve or extend the node diagram.
    - Provide the suggestions in JSON format, including any new nodes and edges.
    - Ensure that the node and edge IDs are unique and do not conflict with existing ones.
    - Include a textual explanation of your suggestions.

    The response should be a JSON object with the following structure:
    {
    "text": "Your explanation to the user.",
    "node_diagram": {
        "nodes": [ ... ],
        "edges": [ ... ]
    }
    }

    The "text" should be short simple and informative and engaging to the user.
    The "node_diagram" could be empty if no changes are needed and depending on the user's message.
    Sometimes the user might ask for ideas and just chat with you, in that case, you can just chat back with them no need to provide a node diagram immediately.
    So in cases where you don't have any suggestions for the node diagram, you can just chat with the user. 
    In the case you provide a node diagram, provide the full flow of the diagram with all the nodes and edges.
 
    The following is all you need to know about the imagineKit's Node, Edge and UIComponent structure:
    Here are the mongoose schamas for Nodes and Edges:
        InputOutputSchema ={
            id: {
                type: String,
                required: true,
            },
            label: {
                type: String,
            },
            value: {
                type: String,
            },
            color: {
                type: String,
            },
        };

        NodeSchema ={
            node_id: {
                type: String,
                required: true,
            },
            type: {
                type: String,
                required: true,
            },
            name: {
                type: String,
                required: true,
            },
            data: {
                inputs: [InputOutputSchema],
                outputs: [InputOutputSchema],
                instruction: { type: String },
                memoryFields: [InputOutputSchema],
            },
            position: {
                x: { type: Number, required: true },
                y: { type: Number, required: true },
            },
            app_id: {
                type: mongoose.Schema.Types.ObjectId,
                ref: App,
                required: true,
            },
        }

        EdgeSchema = {
            source: {
                type: String,
                required: true,
            },
            target: {
                type: String,
                required: true,
            },
            sourceHandle: {
                type: String,
                required: true,
            },
            targetHandle: {
                type: String,
                required: true,
            },
            color: {
                type: String,
            },
        };

        YOU DO NOTE NEED TO PROVIDE THE app_id AS IT IS AUTOMATICALLY GENERATED BY MONGOOSE

        The following are the node types that are available:
            llm,
            imageGen,
            imageDisplay,
            imageTiles,
            sketchPad,
            compare,
            textInput,
            textOutput,
            wordSelector,
            wordArranger,
            flipCard,
            chatInterface,
            memory,

        The following are the node names that are available:
            LLMNode Node,
            ImageGen Node,
            ImagesDisplay Node,
            ImageTiles Node,
            SketchPad Node,
            Compare Node,
            TextInput Node,
            TextOutput Node,
            WordSelector Node,
            WordArranger Node,
            FlipCard Node,
            ChatInterface Node,
            Memory Node,
            CustomNode Node,

        The following are the uiComponents types that are available:
            sketchPad,
            imageDisplay,
            wordSelector
            imageTiles,
            textInput,
            textOutput,
            wordArranger,
            chatInterface,
            flipCard
        
        Now, provide your suggestions based on the user's message and current node editor state.
    `;

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content: prompt,
        },
      ],
      temperature: 0.7,
      max_tokens: 16384,
    });

    return new NextResponse(
      JSON.stringify(response.choices[0].message.content),
      {
        status: 200,
      }
    );
  } catch (error: any) {
    return new NextResponse(JSON.stringify({ error: error.message }), {
      status: 500,
    });
  }
}
